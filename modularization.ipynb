{"cells":[{"cell_type":"code","source":["import os\n","import zipfile\n","\n","from pathlib import Path\n","\n","import requests\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader"],"metadata":{"id":"e64hNa7fEH3D","executionInfo":{"status":"ok","timestamp":1711281677779,"user_tz":-480,"elapsed":435,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}}},"id":"e64hNa7fEH3D","execution_count":13,"outputs":[]},{"cell_type":"markdown","id":"9a418f75","metadata":{"id":"9a418f75"},"source":["## Cell Mode"]},{"cell_type":"code","execution_count":14,"id":"2101f464","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2101f464","executionInfo":{"status":"ok","timestamp":1711281678968,"user_tz":-480,"elapsed":803,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"1fcce448-b520-4744-e801-e1a5a5f7424c"},"outputs":[{"output_type":"stream","name":"stdout","text":["data/pizza_steak_sushi directory exists.\n","Downloading pizza, steak, sushi data...\n","Unzipping pizza, steak, sushi data...\n"]}],"source":["# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"pizza_steak_sushi\"\n","\n","# If the image folder doesn't exist, download it and prepare it...\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory, creating one...\")\n","    image_path.mkdir(parents=True, exist_ok=True)\n","\n","# Download pizza, steak, sushi data\n","with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n","    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n","    print(\"Downloading pizza, steak, sushi data...\")\n","    f.write(request.content)\n","\n","# Unzip pizza, steak, sushi data\n","with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n","    print(\"Unzipping pizza, steak, sushi data...\")\n","    zip_ref.extractall(image_path)\n","\n","# Remove zip file\n","os.remove(data_path / \"pizza_steak_sushi.zip\")"]},{"cell_type":"code","execution_count":15,"id":"6abbb8e8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6abbb8e8","executionInfo":{"status":"ok","timestamp":1711281678968,"user_tz":-480,"elapsed":8,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"c01393e6-4b54-468f-b0e5-35a2d58d5684"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(PosixPath('data/pizza_steak_sushi/train'),\n"," PosixPath('data/pizza_steak_sushi/test'))"]},"metadata":{},"execution_count":15}],"source":["# Setup train and testing paths\n","train_dir = image_path / \"train\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"]},{"cell_type":"code","execution_count":16,"id":"d72a5bed","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d72a5bed","executionInfo":{"status":"ok","timestamp":1711281678968,"user_tz":-480,"elapsed":7,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"e4bb200b-a703-48bf-9b0e-9c3b5e6b6043"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train data:\n","Dataset ImageFolder\n","    Number of datapoints: 225\n","    Root location: data/pizza_steak_sushi/train\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n","               ToTensor()\n","           )\n","Test data:\n","Dataset ImageFolder\n","    Number of datapoints: 75\n","    Root location: data/pizza_steak_sushi/test\n","    StandardTransform\n","Transform: Compose(\n","               Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n","               ToTensor()\n","           )\n"]}],"source":["# Create simple transform\n","data_transform = transforms.Compose([\n","    transforms.Resize((64, 64)),\n","    transforms.ToTensor(),\n","])\n","\n","# Use ImageFolder to create dataset(s)\n","train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n","                                  transform=data_transform, # transforms to perform on data (images)\n","                                  target_transform=None) # transforms to perform on labels (if necessary)\n","\n","test_data = datasets.ImageFolder(root=test_dir,\n","                                 transform=data_transform)\n","\n","print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"]},{"cell_type":"code","execution_count":17,"id":"3e53db45","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3e53db45","executionInfo":{"status":"ok","timestamp":1711281678969,"user_tz":-480,"elapsed":7,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"3388ab6f-5a7f-4641-92bf-59420884f8f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['pizza', 'steak', 'sushi']"]},"metadata":{},"execution_count":17}],"source":["# Get class names as a list\n","class_names = train_data.classes\n","class_names"]},{"cell_type":"code","execution_count":18,"id":"0951d771","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0951d771","executionInfo":{"status":"ok","timestamp":1711281678969,"user_tz":-480,"elapsed":5,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"6c30fe4f-41e1-46f0-d0e1-69ed9f9a8f53"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'pizza': 0, 'steak': 1, 'sushi': 2}"]},"metadata":{},"execution_count":18}],"source":["# Can also get class names as a dict\n","class_dict = train_data.class_to_idx\n","class_dict"]},{"cell_type":"code","execution_count":19,"id":"ea080ab2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ea080ab2","executionInfo":{"status":"ok","timestamp":1711281678969,"user_tz":-480,"elapsed":4,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"4a3a32c8-9c6c-4b4f-a2b0-4e70fc1eb16a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(<torch.utils.data.dataloader.DataLoader at 0x7b1d78d01de0>,\n"," <torch.utils.data.dataloader.DataLoader at 0x7b1d78d02b30>)"]},"metadata":{},"execution_count":19}],"source":["# Turn train and test Datasets into DataLoaders\n","from torch.utils.data import DataLoader\n","train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=1, # how many samples per batch?\n","                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n","                              shuffle=True) # shuffle the data?\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=1,\n","                             num_workers=1,\n","                             shuffle=False) # don't usually need to shuffle testing data\n","\n","train_dataloader, test_dataloader"]},{"cell_type":"code","execution_count":20,"id":"91e87ef4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"91e87ef4","executionInfo":{"status":"ok","timestamp":1711281679384,"user_tz":-480,"elapsed":418,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"be5cb8d6-97db-4b46-8acb-21952d7e9da9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Image shape: torch.Size([1, 3, 64, 64]) -> [batch_size, color_channels, height, width]\n","Label shape: torch.Size([1])\n"]}],"source":["# Check out single image size/shape\n","img, label = next(iter(train_dataloader))\n","\n","# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n","print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n","print(f\"Label shape: {label.shape}\")"]},{"cell_type":"markdown","source":["## Script Mode"],"metadata":{"id":"oHJG_MLnEV_A"},"id":"oHJG_MLnEV_A"},{"cell_type":"code","source":["# Create a directory `modularization` scripts\n","os.makedirs(\"modularization\")"],"metadata":{"id":"ejkAlYFVEW_j","executionInfo":{"status":"ok","timestamp":1711281679384,"user_tz":-480,"elapsed":7,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}}},"id":"ejkAlYFVEW_j","execution_count":21,"outputs":[]},{"cell_type":"code","source":["%%writefile modularization/data_setup.py\n","\"\"\"\n","Contains functionality for creating PyTorch DataLoader's for image classification data.\n","\"\"\"\n","import os\n","\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","\n","NUM_WORKERS = os.cpu_count()\n","\n","def create_dataloaders(\n","  train_dir: str,\n","  test_dir: str,\n","  transform: transforms.Compose,\n","  batch_size: int,\n","  num_workers: int=NUM_WORKERS\n","):\n","  \"\"\"Creates training and testing DataLoaders.\n","\n","  Takes in a training directory and testing directroy path and turns them into\n","  PyTorch Datasets and then into PyTorch DataLoaders.\n","\n","  Args:\n","    train_dir: Path to training directory.\n","    test_dir: Path to testing directory.\n","    transform: torchvision transforms to perform on training and testing data.\n","    batch_size: Number of samples per batch in each of the DataLoaders.\n","    num_workers: An integer for number of workers per DataLoader.\n","\n","  Returns:\n","    A tuple of (train_dataloader, test_dataloader, class_names).\n","    Where class_names is a list of the target classes.\n","    Example usage:\n","      train_dataloader, test_dataloader, class_names = create_dataloaders(train_dir=path/to/train_dir,\n","        test_dir=path/to/test_dir,\n","        transform=some_transform,\n","        batch_size=32,\n","        num_workers=4)\n","  \"\"\"\n","  # Use ImageFolder to create datasets\n","  train_data = datasets.ImageFolder(root=train_dir, transform=transform)\n","  test_data = datasets.ImageFolder(root=test_dir, transform=transform)\n","\n","  # Get class names\n","  class_names = train_data.classes\n","\n","  # Turn images into DataLoader\n","  train_dataloader = DataLoader(\n","    train_data,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","  )\n","\n","  test_dataloader = DataLoader(\n","    test_data,\n","    batch_size=batch_size,\n","    shuffle=False,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","  )\n","\n","  return train_dataloader, test_dataloader, class_names"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f3Swn7KBRyND","executionInfo":{"status":"ok","timestamp":1711281679385,"user_tz":-480,"elapsed":7,"user":{"displayName":"YungShun Chang","userId":"16917011985937891008"}},"outputId":"6c484106-faed-4d47-a179-2514e9b74416"},"id":"f3Swn7KBRyND","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Writing modularization/data_setup.py\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}